import numpy as np
import matplotlib.pyplot as plt
import gzip
import pickle
import os
import random
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (classification_report, accuracy_score, precision_score,
                             recall_score, f1_score)
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import tensorflow as tf
from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense
from keras.models import Sequential
from keras.metrics import Precision, Recall
import idx2numpy


#Constants 
#Paths to dataset files
train_images_path = 'train-images-idx3-ubyte.gz'
train_labels_path = 'train-labels-idx1-ubyte.gz'
test_images_path = 't10k-images-idx3-ubyte.gz'
test_labels_path = 't10k-labels-idx1-ubyte.gz'



#DATASET LOADING 
def load_images(filename, num_images):
    with gzip.open(filename, 'r') as f:
        f.read(16)  #Skip the header, since the first 16 bytes are metadata 
        buf = f.read(28 * 28 * num_images)
        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)
        return data.reshape(num_images, 28 * 28) / 255  #normalize and flatten the data HERE 


def load_labels(filename, num_labels):
    with gzip.open(filename, 'r') as f:
        f.read(8)  #Skip the header, first 8 of lables is metadata 
        buf = f.read(num_labels)
        labels = np.frombuffer(buf, dtype=np.uint8)
    return labels


def save_model(filename, model):
    with open(filename, 'wb') as f:
        pickle.dump(model, f)
    print(f"Model saved to {filename}")

def load_model(filename):
    with open(filename, 'rb') as f:
        model = pickle.load(f)
    print(f"Model loaded from {filename}")
    return model


#Now load the datasets
train_images = load_images(train_images_path, 60000)
train_labels = load_labels(train_labels_path, 60000)
test_images = load_images(test_images_path, 10000)
test_labels = load_labels(test_labels_path, 10000)

#Logistic regression specific functions
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def compute_cost(X, y, weights):
    m = len(y)
    predictions = sigmoid(np.dot(X, weights))
    cost = -(1/m) * np.sum(y * np.log(predictions + 1e-9) + (1 - y) * np.log(1 - predictions + 1e-9))
    return cost

def gradient_descent(X, y, weights, learning_rate, iterations):
    m = len(y)
    cost_history = []

    for i in range(iterations):
        predictions = sigmoid(np.dot(X, weights))
        dw = (1/m) * np.dot(X.T, (predictions - y))
        weights -= learning_rate * dw
        cost = compute_cost(X, y, weights)
        cost_history.append(cost)

    return weights, cost_history

def train_one_vs_all(X, y, num_classes, iterations=600, learning_rate=0.25, weights_file='logreg_weights.pkl'):
    n_features = X.shape[1]
    if os.path.exists(weights_file):
        with open(weights_file, 'rb') as f:
            all_weights = pickle.load(f)
    else:
        all_weights = np.zeros((num_classes, n_features))
        for c in range(num_classes):
            print("Training for class:", c)
            y_c = (y == c).astype(int)
            weights_c, cost_history = gradient_descent(X, y_c, np.zeros(n_features), learning_rate, iterations)
            all_weights[c, :] = weights_c
        with open(weights_file, 'wb') as f:
            pickle.dump(all_weights, f)
    return all_weights

def predict_one_vs_all(X, all_weights):
    predictions = np.dot(X, all_weights.T)
    return np.argmax(predictions, axis=1)


#Train the one-vs-all logistic regression model or load if already trained
all_weights = train_one_vs_all(train_images, train_labels, 10)

#Predict on the test set
test_predictions = predict_one_vs_all(test_images, all_weights)

#Calculate accuracy
accuracy = np.mean(test_predictions == test_labels) * 100
print("Test accuracy: {:.2f}%".format(accuracy))

# Predict on the test set with custom logistic regression
test_predictions = predict_one_vs_all(test_images, all_weights)

# Metrics for custom logistic regression
accuracy_custom = accuracy_score(test_labels, test_predictions)
precision_custom = precision_score(test_labels, test_predictions, average='macro')
recall_custom = recall_score(test_labels, test_predictions, average='macro')
f1_score_custom = f1_score(test_labels, test_predictions, average='macro')

print("Custom Logistic Regression Metrics:")
print(f"Accuracy: {accuracy_custom:.2f}")
print(f"Precision: {precision_custom:.2f}")
print(f"Recall: {recall_custom:.2f}")
print(f"F1 Score: {f1_score_custom:.2f}")


#Checking the accuracy vs the sklearn version 
#Initialize and train the logistic regression model
#try 600 instead of 1k for parity 
#logistic_model = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial')
logistic_model = LogisticRegression(max_iter=600, solver='lbfgs', multi_class='multinomial')
logistic_model.fit(train_images, train_labels)  # use train_labels 
#Predict and evaluate
# Metrics for sklearn logistic regression
logistic_predictions = logistic_model.predict(test_images)
print("\nsklearn Logistic Regression Metrics:")
print(classification_report(test_labels, logistic_predictions)) # use test_labels directly






#OH BOY TIME FOR KNN
print("TIME FOR KNN")

def create_or_load_knn_model(train_data, train_labels, k, model_filename='knn_model.pkl'):
    model = load_model(model_filename)
    if model is None:
        model = {'train_data': train_data, 'train_labels': train_labels, 'k': k}
        save_model(model, model_filename)
    return model

# Helper function to compute Euclidean distance
def euclidean_distance(x1, x2):
    return np.sqrt(np.sum((x1 - x2) ** 2))

# Get k nearest neighbors
def get_neighbors(training_set, labels, test_instance, k):
    distances = []
    for index, train_instance in enumerate(training_set):
        dist = euclidean_distance(test_instance, train_instance)
        distances.append((dist, index))
    distances.sort()
    neighbors = [(training_set[i], labels[i]) for _, i in distances[:k]]
    return neighbors

# Predict the class based on neighbors
def predict_classification(neighbors):
    class_votes = {}
    for (instance, label) in neighbors:
        if label in class_votes:
            class_votes[label] += 1
        else:
            class_votes[label] = 1
    return max(class_votes, key=class_votes.get)


def k_nearest_neighbors_from_model(model, test_data):
    predictions = []
    train_data = model['train_data']
    train_labels = model['train_labels']
    k = model['k']

    for index, test_instance in enumerate(test_data):
        if index % 100 == 0:
            print(f"Predicting {index}/{len(test_data)} with k={k}")
        neighbors = get_neighbors(train_data, train_labels, test_instance, k)
        prediction = predict_classification(neighbors)
        predictions.append(prediction)

    return predictions

# Function to calculate accuracy
def calculate_accuracy(predictions, labels):
    correct = np.sum(predictions == labels)
    return (correct / len(labels)) * 100


def k_fold_split(data, labels, n_folds=60):
    indices = np.arange(data.shape[0])
    np.random.shuffle(indices)  # Shuffle the indices to ensure random splitting
    fold_sizes = np.full(n_folds, len(data) // n_folds, dtype=int)
    fold_sizes[:len(data) % n_folds] += 1
    current = 0
    folds = []
    for fold_size in fold_sizes:
        start, stop = current, current + fold_size
        fold_data = data[indices[start:stop]]
        fold_labels = labels[indices[start:stop]]
        folds.append((fold_data, fold_labels))
        current = stop
    return folds


def k_fold_cross_validate(data, labels, n_folds, k_range):
    folds = k_fold_split(data, labels, n_folds)
    k_accuracies = {k: [] for k in k_range}

    for i in range(n_folds):
        train_data = np.vstack([folds[j][0] for j in range(n_folds) if j != i])
        train_labels = np.concatenate([folds[j][1] for j in range(n_folds) if j != i])
        test_data, test_labels = folds[i]

        for k in k_range:
            model = create_or_load_knn_model(train_data, train_labels, k, model_filename=f'knn_model.pkl')
            predictions = k_nearest_neighbors_from_model(model, test_data)
            accuracy = calculate_accuracy(predictions, test_labels)
            k_accuracies[k].append(accuracy)
            print(f"Fold {i+1}, k={k}, Accuracy: {accuracy:.2f}%")

    return {k: np.mean(accuracies) for k, accuracies in k_accuracies.items()}


def find_best_k(k_accuracies):
    best_k = max(k_accuracies, key=k_accuracies.get)
    best_accuracy = k_accuracies[best_k]
    print(f"Best k is {best_k} with an average accuracy of {best_accuracy:.2f}%")
    return best_k, best_accuracy




# Example usage with a smaller dataset for debugging
train_images_small = train_images[:5000]  # Smaller subset
train_labels_small = train_labels[:5000]
test_images_small = test_images[:1000]  # Smaller subset
test_labels_small = test_labels[:1000]


# Flatten the images for kNN
train_images_small_flat = train_images_small.reshape(-1, 28 * 28)
test_images_small_flat = test_images_small.reshape(-1, 28 * 28)

# Define the range of k values to test and number of folds
k_range = range(1, 10)
num_folds = 4
#OPTIMAL K is 4

# Find the optimal k value and the corresponding accuracy using K-Fold Cross-Validation on smaller dataset
#k_accuracies = k_fold_cross_validate(train_images_small_flat, train_labels_small, num_folds, k_range)

# Find the best k from the cross-validation results
#optimal_k, optimal_accuracy = find_best_k(k_accuracies)

# Print the optimal k and its accuracy
#print(f"Optimal k found: {optimal_k} with an average accuracy of {optimal_accuracy:.2f}% across {num_folds} folds.")
#print("Average accuracies per k:", k_accuracies)

# Assuming you still want to save and use a model trained on the entire smaller dataset with the optimal k
#best_model = create_or_load_knn_model(train_images_small_flat, train_labels_small, optimal_k)
#save_model('knn_model.pkl', best_model)

# Load the best model
loaded_knn = load_model('knn_model.pkl')

# Evaluate using the entire small dataset if necessary (not usually part of k-fold validation but useful for final evaluation)
predictions = k_nearest_neighbors_from_model(loaded_knn, test_images_small_flat)  # Ensure test_images_flat is defined
print("Final Model Metrics:")
print(f"Accuracy: {calculate_accuracy(predictions, test_labels_small):.2f}%")
print(f"Precision: {precision_score(test_labels_small, predictions, average='macro'):.2f}")
print(f"Recall: {recall_score(test_labels_small, predictions, average='macro'):.2f}")
print(f"F1 Score: {f1_score(test_labels_small, predictions, average='macro'):.2f}")



#NOW FOR THE SKLEARN IMP
# Create a KNN classifier
knn_classifier = KNeighborsClassifier(n_neighbors=3)
# Train the classifier
knn_classifier.fit(train_images, train_labels)
# Make predictions
predictions = knn_classifier.predict(test_images)
# Evaluate the classifier
print("Accuracy:", accuracy_score(test_labels, predictions))
print("Classification Report:")
print(classification_report(test_labels, predictions))


#CNN impl. 
train_labels_one_hot = tf.keras.utils.to_categorical(train_labels)
test_labels_one_hot = tf.keras.utils.to_categorical(test_labels)

# Reshape the images to (num_samples, 28, 28, 1)
train_images = train_images.reshape((-1, 28, 28, 1))
test_images = test_images.reshape((-1, 28, 28, 1))


print("TIME FOR CNN ")
# Define the CNN model
model_cnn = tf.keras.models.Sequential()
model_cnn.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model_cnn.add(tf.keras.layers.MaxPooling2D((2, 2)))
model_cnn.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))
model_cnn.add(tf.keras.layers.Flatten())
model_cnn.add(tf.keras.layers.Dense(64, activation='relu'))
model_cnn.add(tf.keras.layers.Dense(10, activation='softmax'))

# Compile the CNN model with additional metrics
model_cnn.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])

# Train the CNN model
model_cnn.fit(train_images, train_labels_one_hot, epochs=5, batch_size=64)

# Evaluate the CNN model
cnn_evaluation = model_cnn.evaluate(test_images, test_labels_one_hot)
print("\nCNN Metrics - Loss, Accuracy, Precision, Recall:", cnn_evaluation)





def display_classification(image, true_label, logistic_pred, knn_pred, cnn_pred):
    plt.figure(figsize=(6, 3))
    plt.subplot(1, 2, 1)
    plt.imshow(image.reshape(28, 28), cmap='gray')
    plt.axis('off')
    
    plt.subplot(1, 2, 2)
    plt.axis('off')
    plt.text(0, 0.2, f"True Label: {true_label}\n"
                     f"Logistic Regression: {logistic_pred}\n"
                     f"kNN: {knn_pred}\n"
                     f"CNN: {cnn_pred}",
             fontdict={'size': 16, 'color': 'black'}, verticalalignment='top')
    plt.savefig('Results.png', dpi=900)
    plt.show()

# Function to get predictions from all models
def classify_image(test_image, test_label, logistic_model, knn_model, cnn_model, k=3):
    # Logistic Regression and CNN predictions
    logistic_pred = logistic_model.predict(test_image.reshape(1, -1))[0]
    cnn_pred = np.argmax(cnn_model.predict(test_image.reshape(1, 28, 28, 1)), axis=1)[0]

    # kNN prediction
    neighbors = get_neighbors(train_images_small_flat, train_labels, test_image, k)
    knn_pred = predict_classification(neighbors)

    # Display classification results along with the image
    display_classification(test_image, test_label, logistic_pred, knn_pred, cnn_pred)

# Randomly select an image and classify it
random_idx = random.randint(0, len(test_images_small_flat) - 1)
random_test_image = test_images_small_flat[random_idx]
random_test_label = test_labels[random_idx]

# Assuming models are already trained and available as logistic_model, model_cnn
classify_image(random_test_image, random_test_label, logistic_model, loaded_knn, model_cnn)
